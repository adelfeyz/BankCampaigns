{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Application III: Comparing Classifiers\n",
    "\n",
    "**Overview**: In this practical application, your goal is to compare the performance of the classifiers we encountered in this section, namely K Nearest Neighbor, Logistic Regression, Decision Trees, and Support Vector Machines.  We will utilize a dataset related to marketing bank products over the telephone.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started\n",
    "\n",
    "Our dataset comes from the UCI Machine Learning repository [link](https://archive.ics.uci.edu/ml/datasets/bank+marketing).  The data is from a Portugese banking institution and is a collection of the results of multiple marketing campaigns.  We will make use of the article accompanying the dataset [here](CRISP-DM-BANK.pdf) for more information on the data and features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: Understanding the Data\n",
    "\n",
    "To gain a better understanding of the data, please read the information provided in the UCI link above, and examine the **Materials and Methods** section of the paper.  How many marketing campaigns does this data represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data from the Portuguese bank's marketing campaigns, as described in the Materials and Methods section of the document, represents 17 campaigns conducted between May 2008 and November 2010. These campaigns resulted in a total of 79,354 contacts​(CRISP-DM-BANK)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Read in the Data\n",
    "\n",
    "Use pandas to read in the dataset `bank-additional-full.csv` and assign to a meaningful variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/bank-additional-full.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
       "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          93.994          -36.4      4.857       5191.0  no  \n",
       "1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          93.994          -36.4      4.857       5191.0  no  \n",
       "3          93.994          -36.4      4.857       5191.0  no  \n",
       "4          93.994          -36.4      4.857       5191.0  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: Understanding the Features\n",
    "\n",
    "\n",
    "Examine the data description below, and determine if any of the features are missing values or need to be coerced to a different data type.\n",
    "\n",
    "\n",
    "```\n",
    "Input variables:\n",
    "# bank client data:\n",
    "1 - age (numeric)\n",
    "2 - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
    "3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
    "4 - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
    "5 - default: has credit in default? (categorical: 'no','yes','unknown')\n",
    "6 - housing: has housing loan? (categorical: 'no','yes','unknown')\n",
    "7 - loan: has personal loan? (categorical: 'no','yes','unknown')\n",
    "# related with the last contact of the current campaign:\n",
    "8 - contact: contact communication type (categorical: 'cellular','telephone')\n",
    "9 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
    "10 - day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n",
    "11 - duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
    "# other attributes:\n",
    "12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
    "14 - previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "15 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
    "# social and economic context attributes\n",
    "16 - emp.var.rate: employment variation rate - quarterly indicator (numeric)\n",
    "17 - cons.price.idx: consumer price index - monthly indicator (numeric)\n",
    "18 - cons.conf.idx: consumer confidence index - monthly indicator (numeric)\n",
    "19 - euribor3m: euribor 3 month rate - daily indicator (numeric)\n",
    "20 - nr.employed: number of employees - quarterly indicator (numeric)\n",
    "\n",
    "Output variable (desired target):\n",
    "21 - y - has the client subscribed a term deposit? (binary: 'yes','no')\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Types:\n",
      "age                 int64\n",
      "job                object\n",
      "marital            object\n",
      "education          object\n",
      "default            object\n",
      "housing            object\n",
      "loan               object\n",
      "contact            object\n",
      "month              object\n",
      "day_of_week        object\n",
      "duration            int64\n",
      "campaign            int64\n",
      "pdays               int64\n",
      "previous            int64\n",
      "poutcome           object\n",
      "emp.var.rate      float64\n",
      "cons.price.idx    float64\n",
      "cons.conf.idx     float64\n",
      "euribor3m         float64\n",
      "nr.employed       float64\n",
      "y                  object\n",
      "dtype: object\n",
      "\n",
      "'Unknown' values in categorical features:\n",
      "job: 330\n",
      "marital: 80\n",
      "education: 1731\n",
      "default: 8597\n",
      "housing: 990\n",
      "loan: 990\n",
      "poutcome: 0\n",
      "\n",
      "Number of 'pdays' = 999: 39673\n"
     ]
    }
   ],
   "source": [
    "# Check the data types\n",
    "print(\"Data Types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Check for 'unknown' values in categorical features\n",
    "categorical_features = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'poutcome']\n",
    "print(\"\\n'Unknown' values in categorical features:\")\n",
    "for feature in categorical_features:\n",
    "    print(f\"{feature}: {df[feature].value_counts().get('unknown', 0)}\")\n",
    "\n",
    "# Check for 'pdays' special case (value = 999)\n",
    "pdays_special_case_count = df['pdays'].value_counts().get(999, 0)\n",
    "print(f\"\\nNumber of 'pdays' = 999: {pdays_special_case_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after cleaning:\n",
      "age                  0\n",
      "job                330\n",
      "marital             80\n",
      "education         1731\n",
      "default           8597\n",
      "housing            990\n",
      "loan               990\n",
      "contact              0\n",
      "month                0\n",
      "day_of_week          0\n",
      "duration             0\n",
      "campaign             0\n",
      "pdays                0\n",
      "previous             0\n",
      "poutcome             0\n",
      "emp.var.rate         0\n",
      "cons.price.idx       0\n",
      "cons.conf.idx        0\n",
      "euribor3m            0\n",
      "nr.employed          0\n",
      "y                    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Replace 'unknown' values with NaN in all columns\n",
    "df_cleaned = df.replace('unknown', np.nan)\n",
    "\n",
    "# Display the number of missing values in each column after replacing 'unknown'\n",
    "print(\"Missing values after cleaning:\")\n",
    "print(df_cleaned.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default\n",
      "no         32588\n",
      "unknown     8597\n",
      "yes            3\n",
      "Name: count, dtype: int64\n",
      "marital\n",
      "married     24928\n",
      "single      11568\n",
      "divorced     4612\n",
      "unknown        80\n",
      "Name: count, dtype: int64\n",
      "education\n",
      "university.degree      12168\n",
      "high.school             9515\n",
      "basic.9y                6045\n",
      "professional.course     5243\n",
      "basic.4y                4176\n",
      "basic.6y                2292\n",
      "unknown                 1731\n",
      "illiterate                18\n",
      "Name: count, dtype: int64\n",
      "housing\n",
      "yes        21576\n",
      "no         18622\n",
      "unknown      990\n",
      "Name: count, dtype: int64\n",
      "loan\n",
      "no         33950\n",
      "yes         6248\n",
      "unknown      990\n",
      "Name: count, dtype: int64\n",
      "job\n",
      "admin.           10422\n",
      "blue-collar       9254\n",
      "technician        6743\n",
      "services          3969\n",
      "management        2924\n",
      "retired           1720\n",
      "entrepreneur      1456\n",
      "self-employed     1421\n",
      "housemaid         1060\n",
      "unemployed        1014\n",
      "student            875\n",
      "unknown            330\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display unique values of 'default' column with their counts\n",
    "print(df['default'].value_counts())\n",
    "print(df['marital'].value_counts())\n",
    "print(df['education'].value_counts())\n",
    "print(df['housing'].value_counts())\n",
    "print(df['loan'].value_counts())\n",
    "print(df['job'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning Description\n",
    "Based on the data for several categorical fields such as default, marital, education, and housing, the cleaning process will focus on handling the 'unknown' values:\n",
    "\n",
    "### Default:\n",
    "The default column contains 8,597 instances of 'unknown' values, which is significant compared to the 32,588 instances of 'no' and only 3 instances of 'yes'. So this field eliminated from data source.\n",
    "\n",
    "### Marital:\n",
    "The marital column has 80 'unknown' values compared to a much larger distribution of known values like 'married' (24,928), 'single' (11,568), and 'divorced' (4,612). The number of 'unknown' values is small, so they can either be removed from dataset.\n",
    "\n",
    "### Education:\n",
    "In the education column, there are 1,731 'unknown' values. This is a larger proportion compared to other categories such as 'university.degree' (12,168) and 'high.school' (9,515). Imputation strategies could involve assigning 'unknown' values to the most frequent category or using predictive models based on other features.\n",
    "\n",
    "### Housing:\n",
    "The housing column contains 990 'unknown' values out of 40,188 total instances, with the majority being 'yes' (21,576) or 'no' (18,622). Since the proportion of 'unknown' values is small, we could remove unkown values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41108, 20)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the column default from data source\n",
    "df = df.drop(columns=['default'])\n",
    "\n",
    "# remove the unknown values from marital field\n",
    "df = df[df['marital'] != 'unknown']\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "education\n",
      "university.degree      13859\n",
      "high.school             9501\n",
      "basic.9y                6037\n",
      "professional.course     5237\n",
      "basic.4y                4170\n",
      "basic.6y                2286\n",
      "illiterate                18\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Impute 'unknown' values in the 'education' column with the most frequent category\n",
    "most_frequent_education = df['education'].value_counts().idxmax()\n",
    "\n",
    "# Replace 'unknown' values with the most frequent value\n",
    "df['education'] = df['education'].replace('unknown', most_frequent_education)\n",
    "\n",
    "# Verify the imputation by checking the unique values and their counts in the 'education' column\n",
    "print(df['education'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "housing\n",
      "yes    21541\n",
      "no     18578\n",
      "Name: count, dtype: int64\n",
      "New dataframe shape: (40119, 20)\n"
     ]
    }
   ],
   "source": [
    "# Drop rows where 'housing' is 'unknown'\n",
    "df = df[df['housing'] != 'unknown']\n",
    "\n",
    "# Verify that the 'unknown' values are removed by checking the unique values and their counts in the 'housing' column\n",
    "print(df['housing'].value_counts())\n",
    "\n",
    "# Check the shape of the new dataframe to confirm rows were dropped\n",
    "print(\"New dataframe shape:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loan column value counts after cleaning:\n",
      "loan\n",
      "no     33620\n",
      "yes     6183\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Job column value counts after cleaning:\n",
      "job\n",
      "admin.           10181\n",
      "blue-collar       9001\n",
      "technician        6584\n",
      "services          3862\n",
      "management        2850\n",
      "retired           1671\n",
      "entrepreneur      1417\n",
      "self-employed     1376\n",
      "housemaid         1028\n",
      "unemployed         982\n",
      "student            851\n",
      "Name: count, dtype: int64\n",
      "\n",
      "New dataframe shape: (39803, 20)\n"
     ]
    }
   ],
   "source": [
    "# Drop rows where 'loan' is 'unknown'\n",
    "df = df[df['loan'] != 'unknown']\n",
    "\n",
    "# Drop rows where 'job' is 'unknown'\n",
    "df = df[df['job'] != 'unknown']\n",
    "\n",
    "# Verify that 'unknown' values are removed by checking the unique values and their counts in the 'loan' and 'job' columns\n",
    "print(\"Loan column value counts after cleaning:\")\n",
    "print(df['loan'].value_counts())\n",
    "\n",
    "print(\"\\nJob column value counts after cleaning:\")\n",
    "print(df['job'].value_counts())\n",
    "\n",
    "# Check the shape of the new dataframe to confirm rows were dropped\n",
    "print(\"\\nNew dataframe shape:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4: Understanding the Task\n",
    "\n",
    "After examining the description and data, your goal now is to clearly state the *Business Objective* of the task.  State the objective below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 39803 entries, 0 to 41187\n",
      "Data columns (total 20 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   age             39803 non-null  int64  \n",
      " 1   job             39803 non-null  object \n",
      " 2   marital         39803 non-null  object \n",
      " 3   education       39803 non-null  object \n",
      " 4   housing         39803 non-null  object \n",
      " 5   loan            39803 non-null  object \n",
      " 6   contact         39803 non-null  object \n",
      " 7   month           39803 non-null  object \n",
      " 8   day_of_week     39803 non-null  object \n",
      " 9   duration        39803 non-null  int64  \n",
      " 10  campaign        39803 non-null  int64  \n",
      " 11  pdays           39803 non-null  int64  \n",
      " 12  previous        39803 non-null  int64  \n",
      " 13  poutcome        39803 non-null  object \n",
      " 14  emp.var.rate    39803 non-null  float64\n",
      " 15  cons.price.idx  39803 non-null  float64\n",
      " 16  cons.conf.idx   39803 non-null  float64\n",
      " 17  euribor3m       39803 non-null  float64\n",
      " 18  nr.employed     39803 non-null  float64\n",
      " 19  y               39803 non-null  object \n",
      "dtypes: float64(5), int64(5), object(10)\n",
      "memory usage: 6.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Business Objective:\n",
    "\n",
    "The goal of this project is to develop a predictive model that can accurately determine whether a customer will subscribe to a term deposit based on data from direct marketing campaigns of a Portuguese bank. By analyzing various customer attributes (e.g., job, education, marital status) and campaign-related data (e.g., number of contacts, previous outcomes), the objective is to improve the efficiency of future marketing campaigns by targeting potential customers who are more likely to subscribe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5: Engineering Features\n",
    "\n",
    "Now that you understand your business objective, we will build a basic model to get started.  Before we can do this, we must work to encode the data.  Using just the bank information features, prepare the features and target column for modeling with appropriate encoding and transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3f/lc4jd68n66l59h52jtwhnzq00000gn/T/ipykernel_22286/831738495.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['housing'] = label_encoder.fit_transform(X['housing'])\n",
      "/var/folders/3f/lc4jd68n66l59h52jtwhnzq00000gn/T/ipykernel_22286/831738495.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['loan'] = label_encoder.fit_transform(X['loan'])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "# Select features (removing 'default', 'balance', and 'day')\n",
    "features = ['age', 'job', 'marital', 'education', 'housing', 'loan', 'contact', 'month', 'campaign', 'pdays', 'previous', 'poutcome']\n",
    "target = 'y'\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Encode the target variable ('yes' -> 1, 'no' -> 0)\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Apply Label Encoding to 'housing' and 'loan' fields\n",
    "X['housing'] = label_encoder.fit_transform(X['housing'])\n",
    "X['loan'] = label_encoder.fit_transform(X['loan'])\n",
    "\n",
    "# One-Hot Encoding for categorical variables\n",
    "categorical_features = ['job', 'marital', 'education', 'contact', 'month', 'poutcome']\n",
    "X_encoded = pd.get_dummies(X, columns=categorical_features, drop_first=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6: Train/Test Split\n",
    "\n",
    "With your data prepared, split it into a train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (31842, 36)\n",
      "Test features shape: (7961, 36)\n",
      "Target distribution in train set: 0    28241\n",
      "1     3601\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Verify the prepared data\n",
    "print(\"Training features shape:\", X_train.shape)\n",
    "print(\"Test features shape:\", X_test.shape)\n",
    "print(\"Target distribution in train set:\", pd.Series(y_train).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 7: A Baseline Model\n",
    "\n",
    "Before we build our first model, we want to establish a baseline.  What is the baseline performance that our classifier should aim to beat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy by predicting the majority class ('no'): 0.8873\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Identify the majority class in the target\n",
    "majority_class = y.value_counts().idxmax()\n",
    "\n",
    "# Calculate the baseline accuracy (predicting the majority class for every instance)\n",
    "baseline_accuracy = (y == majority_class).mean()\n",
    "\n",
    "print(f\"Baseline accuracy by predicting the majority class ('{majority_class}'): {baseline_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 8: A Simple Model\n",
    "\n",
    "Use Logistic Regression to build a basic model on your data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8979\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95      7075\n",
      "           1       0.65      0.18      0.28       886\n",
      "\n",
      "    accuracy                           0.90      7961\n",
      "   macro avg       0.78      0.59      0.61      7961\n",
      "weighted avg       0.88      0.90      0.87      7961\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adelfeyz/micromamba/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target variable on the test set\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_report_output = classification_report(y_test, y_pred)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 9: Score the Model\n",
    "\n",
    "What is the accuracy of your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8979\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 10: Model Comparisons\n",
    "\n",
    "Now, we aim to compare the performance of the Logistic Regression model to our KNN algorithm, Decision Tree, and SVM models.  Using the default settings for each of the models, fit and score each.  Also, be sure to compare the fit time of each of the models.  Present your findings in a `DataFrame` similar to that below:\n",
    "\n",
    "| Model | Train Time | Train Accuracy | Test Accuracy |\n",
    "| ----- | ---------- | -------------  | -----------   |\n",
    "|     |    |.     |.     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adelfeyz/micromamba/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Train Time  Train Accuracy  Test Accuracy\n",
      "0  Logistic Regression    4.113285        0.896489       0.897877\n",
      "1                  KNN    0.011316        0.907418       0.893732\n",
      "2        Decision Tree    0.161488        0.982319       0.840724\n",
      "3                  SVM    8.221289        0.896646       0.901017\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize models\n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "knn = KNeighborsClassifier()\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "svm = SVC(random_state=42)\n",
    "\n",
    "# Function to fit model, record train/test accuracy, and time\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "    train_accuracy = accuracy_score(y_train, model.predict(X_train))\n",
    "    test_accuracy = accuracy_score(y_test, model.predict(X_test))\n",
    "    return train_time, train_accuracy, test_accuracy\n",
    "\n",
    "# Evaluate each model\n",
    "models = {\n",
    "    \"Logistic Regression\": log_reg,\n",
    "    \"KNN\": knn,\n",
    "    \"Decision Tree\": decision_tree,\n",
    "    \"SVM\": svm\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    train_time, train_accuracy, test_accuracy = evaluate_model(model, X_train, X_test, y_train, y_test)\n",
    "    results.append([model_name, train_time, train_accuracy, test_accuracy])\n",
    "\n",
    "# Create DataFrame to display results\n",
    "df_results = pd.DataFrame(results, columns=[\"Model\", \"Train Time\", \"Train Accuracy\", \"Test Accuracy\"])\n",
    "\n",
    "# Display the results\n",
    "print(df_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 11: Improving the Model\n",
    "\n",
    "Now that we have some basic models on the board, we want to try to improve these.  Below, we list a few things to explore in this pursuit.\n",
    "\n",
    "- More feature engineering and exploration.  For example, should we keep the gender feature?  Why or why not?\n",
    "- Hyperparameter tuning and grid search.  All of our models have additional hyperparameters to tune and explore.  For example the number of neighbors in KNN or the maximum depth of a Decision Tree.  \n",
    "- Adjust your performance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best KNN params: {'n_neighbors': 15}\n",
      "Best KNN score: 0.8952012328481788\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "param_grid = {'n_neighbors': [3, 5, 10, 15]}\n",
    "grid_search_knn = GridSearchCV(knn, param_grid, cv=5)\n",
    "grid_search_knn.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best KNN params:\", grid_search_knn.best_params_)\n",
    "print(\"Best KNN score:\", grid_search_knn.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Decision Tree params: {'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 2}\n",
      "Best Decision Tree score: 0.8965203480505053\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'max_depth': [3, 5, 10], 'min_samples_split': [2, 4, 6], 'min_samples_leaf': [1, 2, 4]}\n",
    "grid_search_tree = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid, cv=5)\n",
    "grid_search_tree.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Decision Tree params:\", grid_search_tree.best_params_)\n",
    "print(\"Best Decision Tree score:\", grid_search_tree.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adelfeyz/micromamba/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/adelfeyz/micromamba/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/adelfeyz/micromamba/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/adelfeyz/micromamba/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/adelfeyz/micromamba/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/adelfeyz/micromamba/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/adelfeyz/micromamba/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/adelfeyz/micromamba/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/adelfeyz/micromamba/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/adelfeyz/micromamba/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/adelfeyz/micromamba/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/adelfeyz/micromamba/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Logistic Regression params: {'C': 0.1, 'solver': 'liblinear'}\n",
      "Best Logistic Regression score: 0.8962690720441586\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [0.1, 1, 10], 'solver': ['lbfgs', 'liblinear']}\n",
    "grid_search_logreg = GridSearchCV(LogisticRegression(max_iter=1000, random_state=42), param_grid, cv=5)\n",
    "grid_search_logreg.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Logistic Regression params:\", grid_search_logreg.best_params_)\n",
    "print(\"Best Logistic Regression score:\", grid_search_logreg.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.1, 1], 'kernel': ['linear']}\n",
    "grid_search_svm = GridSearchCV(SVC(random_state=42), param_grid, cv=5)\n",
    "grid_search_svm.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best SVM params:\", grid_search_svm.best_params_)\n",
    "print(\"Best SVM score:\", grid_search_svm.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculating precision, recall, and F1 score for the KNN model\n",
    "y_pred_knn = grid_search_knn.predict(X_test)\n",
    "precision_knn = precision_score(y_test, y_pred_knn)\n",
    "recall_knn = recall_score(y_test, y_pred_knn)\n",
    "f1_knn = f1_score(y_test, y_pred_knn)\n",
    "\n",
    "print(f\"KNN Precision: {precision_knn:.4f}, Recall: {recall_knn:.4f}, F1 Score: {f1_knn:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating precision, recall, and F1 score for the Decision tree model\n",
    "y_pred_tree = grid_search_tree.predict(X_test)\n",
    "precision_tree = precision_score(y_test, y_pred_tree)\n",
    "recall_tree = recall_score(y_test, y_pred_tree)\n",
    "f1_tree = f1_score(y_test, y_pred_tree)\n",
    "\n",
    "print(f\"KNN Precision: {precision_tree:.4f}, Recall: {recall_tree:.4f}, F1 Score: {f1_tree:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating precision, recall, and F1 score for the logreg model\n",
    "y_pred_logreg = grid_search_logreg.predict(X_test)\n",
    "precision_logreg = precision_score(y_test, y_pred_logreg)\n",
    "recall_logreg = recall_score(y_test, y_pred_logreg)\n",
    "f1_logreg = f1_score(y_test, y_pred_logreg)\n",
    "\n",
    "print(f\"KNN Precision: {precision_logreg:.4f}, Recall: {recall_logreg:.4f}, F1 Score: {f1_logreg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating precision, recall, and F1 score for the SVM model\n",
    "y_pred_svm = grid_search_svm.predict(X_test)\n",
    "precision_svm = precision_score(y_test, y_pred_svm)\n",
    "recall_svm = recall_score(y_test, y_pred_svm)\n",
    "f1_svm = f1_score(y_test, y_pred_svm)\n",
    "\n",
    "print(f\"KNN Precision: {precision_svm:.4f}, Recall: {recall_svm:.4f}, F1 Score: {f1_svm:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Questions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
